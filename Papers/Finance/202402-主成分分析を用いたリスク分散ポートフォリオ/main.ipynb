{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import scipy\n",
    "from scipy.optimize import minimize\n",
    "from abc import ABC\n",
    "from abc import abstractmethod\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "files = glob.glob('data/*.csv')\n",
    "files"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81318aa3e706e652",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "file = 'data/global-reit.csv'\n",
    "column = os.path.basename(file).split('.')[0]\n",
    "global_reit = pd.read_csv(file, parse_dates=['基準日']).rename(columns={'基準日': 'date'}).set_index('date')\n",
    "global_reit['分配金'] = global_reit['分配金'].str.replace('-', '0').map(float)\n",
    "global_reit[column] = global_reit['基準価額'] + global_reit['分配金']\n",
    "global_reit = global_reit[[column]]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9fc2c7abce35759",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "file = 'data/japan-reit.csv'\n",
    "column = os.path.basename(file).split('.')[0]\n",
    "japan_reit = pd.read_csv(file, parse_dates=['基準日']).rename(columns={'基準日': 'date'}).set_index('date')\n",
    "japan_reit['分配金'] = japan_reit['分配金'].str.replace('-', '0').map(float)\n",
    "japan_reit[column] = japan_reit['基準価額'] + japan_reit['分配金']\n",
    "japan_reit = japan_reit[[column]]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed62752b5d72de2c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "file = 'data/global-equity.csv'\n",
    "column = os.path.basename(file).split('.')[0]\n",
    "global_equity = pd.read_csv(file, encoding='shift-jis', header=1, parse_dates=['基準日']).rename(columns={'基準日': 'date'}).set_index('date')\n",
    "global_equity = global_equity[['基準価額（分配金再投資）(円)']].rename(columns={'基準価額（分配金再投資）(円)': column})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e68e307b7329d467",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "file = 'data/japan-equity.csv'\n",
    "column = os.path.basename(file).split('.')[0]\n",
    "japan_equity = pd.read_csv(file, encoding='shift-jis', header=1, parse_dates=['基準日']).rename(columns={'基準日': 'date'}).set_index('date')\n",
    "japan_equity = japan_equity[['基準価額（分配金再投資）(円)']].rename(columns={'基準価額（分配金再投資）(円)': column})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7e40de5a4ca50b1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "file = 'data/global-bond.csv'\n",
    "column = os.path.basename(file).split('.')[0]\n",
    "global_bond = pd.read_csv(file, encoding='shift-jis', header=1, parse_dates=['基準日']).rename(columns={'基準日': 'date'}).set_index('date')\n",
    "global_bond = global_bond[['基準価額（分配金再投資）(円)']].rename(columns={'基準価額（分配金再投資）(円)': column})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c462f6b66c314c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "file = 'data/japan-bond.csv'\n",
    "column = os.path.basename(file).split('.')[0]\n",
    "japan_bond = pd.read_csv(file, encoding='shift-jis', header=1, parse_dates=['基準日']).rename(columns={'基準日': 'date'}).set_index('date')\n",
    "japan_bond = japan_bond[['基準価額（分配金再投資）(円)']].rename(columns={'基準価額（分配金再投資）(円)': column})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4cf170aad02c43a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.concat([global_equity, japan_equity, global_bond, japan_bond], axis=1).dropna().sort_index()\n",
    "# df = pd.concat([global_reit, japan_reit, global_equity, japan_equity, global_bond, japan_bond], axis=1).dropna().sort_index()\n",
    "\n",
    "df = df.reset_index().assign(yearmonth=lambda d: d['date'].dt.strftime('%Y-%m')).groupby('yearmonth').last().set_index('date').pct_change().dropna() * 100\n",
    "df.columns, len(df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d12208d4a9bc944c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Simulation(ABC):\n",
    "    def __init__(self, initial_weight, data):\n",
    "        self.initial_weight = initial_weight\n",
    "        self.data = data\n",
    "        self.cov = data.cov().to_numpy()\n",
    "        self.eigenvalues, self.eigenvectors = np.linalg.eig(self.cov)\n",
    "        \n",
    "    def compute_information(self, weight):\n",
    "        weight_pc = self.eigenvectors.T @ weight\n",
    "        variances = weight_pc * weight_pc * self.eigenvalues\n",
    "        probs = variances / variances.sum()\n",
    "        information = -probs * np.log(probs)\n",
    "        return information\n",
    "    \n",
    "    def compute(self):\n",
    "        weight = self.compute_weight()\n",
    "        return {'weight_asset': weight, 'cov': self.cov, 'eigenvalues': self.eigenvalues, 'eigenvectors': self.eigenvectors, 'information': self.compute_information(weight)}\n",
    "    \n",
    "    @abstractmethod\n",
    "    def compute_weight(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4c6427de9ab51f0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class SimulationSameWeight(Simulation):\n",
    "    def compute_weight(self):\n",
    "        return np.ones(len(self.data.columns)) / len(self.data.columns)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe918d0c01601ef7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class SimulationRiskParity(Simulation):\n",
    "    def compute_weight(self):\n",
    "        sigmas = np.sqrt(np.diag(self.cov))\n",
    "        weight = 1 / sigmas\n",
    "        weight = weight / weight.sum()\n",
    "        return weight"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "379d6bb5ae205867",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class SimulationBenchmark(Simulation):\n",
    "    def compute_weight(self):\n",
    "        name_to_weight = {'global-reit': 0.0, 'japan-reit': 0.0, 'global-equity': 0.1, 'japan-equity': 0.3, 'global-bond': 0.2, 'japan-bond': 0.4}\n",
    "        return df.columns.map(lambda c: name_to_weight[c]).to_numpy()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e26ef5e3a07b3ff",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class SimulationMinimumVariance(Simulation):\n",
    "    def compute_weight(self):\n",
    "        result = minimize(self.compute_variance, self.initial_weight, constraints={'type': 'eq', 'fun': lambda x: 1 - np.sum(x)}, bounds=[(0, 1)] * len(self.data.columns))\n",
    "        return result.x\n",
    "\n",
    "    def compute_variance(self, weight):\n",
    "        variance = weight @ self.cov @ weight\n",
    "        return variance"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51f58b8162509481",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class SimulationPcaVariance(Simulation):\n",
    "    def compute_weight(self):\n",
    "        result = minimize(self.compute_neg_entropy, self.initial_weight, constraints={'type': 'eq', 'fun': lambda x: 1 - np.sum(x)}, bounds=[(0, 1)] * len(self.data.columns))\n",
    "        return result.x\n",
    "\n",
    "    def compute_neg_entropy(self, weight):\n",
    "        entropy = self.compute_information(weight).sum()\n",
    "        return -np.exp(entropy)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3b31c6bc9279d9f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class SimulationPcaKde(Simulation):\n",
    "    def compute_weight(self):\n",
    "        result = minimize(self.compute_neg_entropy, self.initial_weight, constraints={'type': 'eq', 'fun': lambda x: 1 - np.sum(x)}, bounds=[(1e-10, 1)] * len(self.data.columns))\n",
    "        return result.x\n",
    "\n",
    "    def compute_neg_entropy(self, weight):\n",
    "        noise_data = np.random.normal(0, 1e-10, self.data.shape).T\n",
    "        arg = (data.to_numpy() * weight).T + noise_data\n",
    "        \n",
    "        noise_prob = np.abs(np.random.normal(0, 1e-10, arg.shape[1]).T)\n",
    "        prob = np.abs(scipy.stats.gaussian_kde(arg)(data.to_numpy().T)) + noise_prob\n",
    "        prob = prob / prob.sum()\n",
    "        entropy = -np.sum(prob * np.log(prob))\n",
    "        return -entropy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4873ce7c8b7eb197",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def compute(sim: Simulation):\n",
    "    result = sim.compute()\n",
    "    weight_pc = sim.eigenvectors.T @ result['weight_asset']\n",
    "    summary = pd.DataFrame().assign(column=df.columns).assign(date=date).assign(weight=result['weight_asset']).assign(risk=np.sqrt(np.diag(result['cov']) * result['weight_asset'] * result['weight_asset'])).assign(risk_pc=np.sqrt(result['eigenvalues'] * weight_pc * weight_pc)).assign(pc1_ratio=lambda d: d['risk_pc'].max() / d['risk_pc'].sum()).assign(information=result['information']).assign(pl=(result['weight_asset'] * today).tolist()).assign(total_std=np.sqrt(result['weight_asset'] @ result['cov'] @ result['weight_asset'])).set_index(['date', 'column'])\n",
    "    for i in range(len(df.columns)):\n",
    "        summary['eigenvector_' + str(i)] = sim.eigenvectors[i]\n",
    "    return summary"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b86d8ecfb8ceb00e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.index.min(), df.index.max()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51acd3ab649ed69d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "size = 60\n",
    "dates = list(df.index)[size:]\n",
    "summaries = []\n",
    "\n",
    "for date in dates:\n",
    "    print(date)\n",
    "    data = df[df.index < date].tail(size)\n",
    "    today = df[df.index == date].iloc[0]\n",
    "    summaries.append(compute(SimulationPcaVariance(np.ones(len(df.columns)) / len(df.columns), data)).assign(method='pca_variance'))\n",
    "    # summaries.append(compute(SimulationPcaKde(np.ones(len(df.columns)) / len(df.columns), data)).assign(method='pca_kde'))\n",
    "    summaries.append(compute(SimulationRiskParity(np.ones(len(df.columns)) / len(df.columns), data)).assign(method='risk_parity'))\n",
    "    summaries.append(compute(SimulationBenchmark(np.ones(len(df.columns)) / len(df.columns), data)).assign(method='pension_fund'))\n",
    "    summaries.append(compute(SimulationMinimumVariance(np.ones(len(df.columns)) / len(df.columns), data)).assign(method='minimum_variance'))\n",
    "    summaries.append(compute(SimulationSameWeight(np.ones(len(df.columns)) / len(df.columns), data)).assign(method='same_weight'))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7024415bf7bc273",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "result = pd.concat(summaries).reset_index()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f283201ad2331a0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "result"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4f1757246d66ced",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "summation = result.drop(columns=['column']).groupby(['date', 'method']).sum()\n",
    "summation = summation.groupby('method').pl.describe()\n",
    "summation['return (yearly)'] = summation['mean'] * 12\n",
    "summation['std (yearly)'] = summation['std'] * np.sqrt(12)\n",
    "summation['return / std (yearly)'] = summation['return (yearly)'] / summation['std (yearly)']\n",
    "\n",
    "# save df to fig\n",
    "summation[['return (yearly)', 'std (yearly)', 'return / std (yearly)']]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3901935eaaa6c83",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tmp = df[df.index.isin(result.date.unique())]\n",
    "tmp = pd.concat([tmp[[col]].assign(asset=col).rename(columns={col: \"pl\"}) for col in tmp.columns])\n",
    "\n",
    "summation = tmp.groupby('asset').pl.describe()\n",
    "summation['return (yearly)'] = summation['mean'] * 12\n",
    "summation['std (yearly)'] = summation['std'] * np.sqrt(12)\n",
    "summation['return / std (yearly)'] = summation['return (yearly)'] / summation['std (yearly)']\n",
    "\n",
    "summation[['return (yearly)', 'std (yearly)', 'return / std (yearly)']]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45fbaeda9070f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tmp = df[df.index.isin(result.date.unique())].to_numpy()\n",
    "cov = np.cov(tmp.T)\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov)\n",
    "\n",
    "tmp = tmp @ eigenvectors\n",
    "tmp = pd.DataFrame(tmp, columns=[f'pc{i+1}' for i in range(len(df.columns))])\n",
    "tmp = pd.concat([tmp[[col]].assign(pc=col).rename(columns={col: \"pl\"}) for col in tmp.columns])\n",
    "\n",
    "summation = tmp.groupby('pc').pl.describe()\n",
    "summation['return (yearly)'] = summation['mean'] * 12\n",
    "summation['std (yearly)'] = summation['std'] * np.sqrt(12)\n",
    "summation['return / std (yearly)'] = summation['return (yearly)'] / summation['std (yearly)']\n",
    "\n",
    "summation[['return (yearly)', 'std (yearly)', 'return / std (yearly)']]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bae43f03a5ab8253",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "methods = result.method.unique()\n",
    "for method in methods:\n",
    "    print('weight', method)\n",
    "    tmp = result[result.method == method].groupby(['date', 'column']).sum().reset_index().sort_values('date')\n",
    "    tmp = tmp.pivot(index='date', columns='column', values='weight').fillna(0)\n",
    "    for col in df.columns: tmp[col] = tmp[col].abs()\n",
    "\n",
    "    tmp.plot(kind='bar', stacked=True, figsize=(10, 4), title=method)\n",
    "    plt.show()\n",
    "    \n",
    "    tmp.plot(kind='bar', stacked=True, figsize=(10, 4), title=method)\n",
    "    plt.savefig(f'fig/weight_{method}.png')\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acede425b4036cad",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "methods = result.method.unique()\n",
    "for method in methods:\n",
    "    print('risk', method)\n",
    "    tmp = result[result.method == method].groupby(['date', 'column']).sum().reset_index().sort_values('date')\n",
    "    tmp = tmp.pivot(index='date', columns='column', values='risk').fillna(0)\n",
    "    for col in df.columns: tmp[col] = tmp[col].abs()\n",
    "\n",
    "    tmp.plot(kind='bar', stacked=True, figsize=(10, 4), title=method)\n",
    "    plt.show()\n",
    "\n",
    "    tmp.plot(kind='bar', stacked=True, figsize=(10, 4), title=method)\n",
    "    plt.savefig(f'fig/risk_{method}.png')\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "320876fdef5a50ab",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "methods = result.method.unique()\n",
    "for method in methods:\n",
    "    print('risk_pc', method)\n",
    "    tmp = result[result.method == method].groupby(['date', 'column']).sum().reset_index().sort_values('date')\n",
    "    tmp = pd.concat([grp.sort_values('risk_pc', ascending=False).assign(column=[f'risk_pc_{i+1}' for i in range(len(df.columns))]) for by, grp in tmp.groupby(['date'])])\n",
    "    tmp = tmp.pivot(index='date', columns='column', values='risk_pc').fillna(0)\n",
    "\n",
    "    tmp.plot(kind='bar', stacked=True, figsize=(10, 4), title=method)\n",
    "    plt.show()\n",
    "\n",
    "    tmp.plot(kind='bar', stacked=True, figsize=(10, 4), title=method)\n",
    "    plt.savefig(f'fig/risk_pc_{method}.png')\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58f88f5fc2c26b3f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "methods = result.method.unique()\n",
    "for method in methods:\n",
    "    print('information', method)\n",
    "    tmp = result[result.method == method].groupby(['date', 'column']).sum().reset_index().sort_values('date')\n",
    "    tmp = tmp.pivot(index='date', columns='column', values='information').fillna(0)\n",
    "    for col in df.columns: tmp[col] = tmp[col].abs()\n",
    "\n",
    "    tmp.plot(kind='bar', stacked=True, figsize=(10, 4), title=method)\n",
    "    plt.show()\n",
    "\n",
    "    tmp.plot(kind='bar', stacked=True, figsize=(10, 4), title=method)\n",
    "    plt.savefig(f'fig/information_{method}.png')\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "358589ea133e5589",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tmp = result.groupby(['date', 'method']).sum()[['information']].assign(div_index=lambda d: d['information'].map(np.exp)).reset_index()\n",
    "tmp = tmp[['date', 'method', 'div_index']].pivot(index='date', columns='method', values='div_index').fillna(0)\n",
    "\n",
    "tmp.plot(kind='line', stacked=False, figsize=(10, 4), title='div_index')\n",
    "plt.show()\n",
    "\n",
    "tmp.plot(kind='line', stacked=False, figsize=(10, 4), title='div_index')\n",
    "plt.savefig(f'fig/div_index.png')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1a3554685ca6f4d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "methods = result.method.unique()\n",
    "for method in methods:\n",
    "    print('pc1_ratio', method)\n",
    "    tmp = result[result.method == method].drop(columns=['column'])[['date', 'pc1_ratio']].groupby(['date']).mean().reset_index().sort_values('date').set_index('date')\n",
    "    \n",
    "\n",
    "    tmp.plot(kind='line', stacked=True, figsize=(10, 4), title=method)\n",
    "    plt.show()\n",
    "\n",
    "    tmp.plot(kind='line', stacked=True, figsize=(10, 4), title=method)\n",
    "    plt.savefig(f'fig/pc1_ratio_{method}.png')\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b97b40c5f2b1a4c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "methods = result.method.unique()\n",
    "for method in methods[:1]:\n",
    "    tmp = result[result.method == method][['date', 'column'] + [f'eigenvector_{i}' for i in range(len(df.columns))]].groupby(['date', 'column']).mean().reset_index().sort_values('date').set_index('date')\n",
    "    for i in range(len(df.columns)):\n",
    "        print(f'eig_{i}', method)\n",
    "        \n",
    "        plt.figure(figsize=(10, 4))\n",
    "        sns.lineplot(data=tmp, x='date', y='eigenvector_' + str(i), hue='column')\n",
    "        plt.title(f'eigenvector_{i+1}')\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        sns.lineplot(data=tmp, x='date', y='eigenvector_' + str(i), hue='column')\n",
    "        plt.title(f'eigenvector_{i+1}')\n",
    "        plt.savefig(f'fig/eigenvector_{i+1}_{method}.png')\n",
    "        plt.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a48743c2bfebd8f9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tmp = result.drop(columns=['column']).groupby(['date', 'method']).sum().reset_index().sort_values('date')\n",
    "tmp['pl'] = 1 + tmp['pl'] / 100\n",
    "tmp['pl'] = tmp.groupby('method')['pl'].cumprod()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.lineplot(data=tmp, x='date', y='pl', hue='method')\n",
    "plt.title('pl')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.lineplot(data=tmp, x='date', y='pl', hue='method')\n",
    "plt.title('pl')\n",
    "plt.savefig(f'fig/pl_{method}.png')\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91539984fdc4b0cd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b8475f0e2db37762",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c1a17a352b71ee52",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
